{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsu/py36tf1x/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IS_TRAIN=True\n",
    "\n",
    "# leaky relu function\n",
    "def lrelu(X, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * X + f2 * tf.abs(X)\n",
    "\n",
    "def get_conv_weight(name,kshape,wd=0.0005):\n",
    "    #with tf.device('/cpu:0'):\n",
    "    var=tf.get_variable(name,shape=kshape,initializer=tf.contrib.layers.xavier_initializer())\n",
    "    if wd!=0:\n",
    "        weight_decay = tf.nn.l2_loss(var)*wd\n",
    "        tf.add_to_collection('weightdecay_losses', weight_decay)\n",
    "    return var\n",
    "\n",
    "def conv3d(name,l_input,kernel_size, strides=[1,1,1,1,1], padding=\"SAME\", with_w=True):\n",
    "    conv_w=get_conv_weight(name=name+'_conv3d', kshape=kernel_size)\n",
    "    bias_w=get_conv_weight(name+'_bias',[kernel_size[-1]],0)\n",
    "    \n",
    "    conv = tf.nn.bias_add(tf.nn.conv3d(l_input, conv_w, strides=strides, padding=padding), bias_w, name=name)\n",
    "    \n",
    "    if with_w:\n",
    "        return conv, conv_w, bias_w\n",
    "    else:\n",
    "        return conv\n",
    "    \n",
    "def convS(name,l_input,in_channels,out_channels, strides=[1,1,1,1,1], padding='SAME', with_w=True):\n",
    "    conv_w=get_conv_weight(name=name+'_conv3d', kshape=[1,3,3,in_channels,out_channels])\n",
    "    bias_w=get_conv_weight(name+'_bias', [out_channels], 0)\n",
    "    \n",
    "    conv = tf.nn.bias_add(tf.nn.conv3d(l_input, conv_w, strides=strides, padding=padding), bias_w, name=name)\n",
    "    \n",
    "    if with_w:\n",
    "        return conv, conv_w, bias_w\n",
    "    else:\n",
    "        return conv\n",
    "    \n",
    "def convT(name,l_input,in_channels,out_channels, n_t=3, strides=[1,1,1,1,1], padding='SAME', with_w=True):\n",
    "    conv_w=get_conv_weight(name=name+'_conv3d', kshape=[n_t,1,1,in_channels,out_channels])\n",
    "    bias_w=get_conv_weight(name+'_bias', [out_channels], 0)\n",
    "    \n",
    "    conv = tf.nn.bias_add(tf.nn.conv3d(l_input, conv_w, strides=strides, padding=padding), bias_w, name=name)\n",
    "    \n",
    "    if with_w:\n",
    "        return conv, conv_w, bias_w\n",
    "    else:\n",
    "        return conv\n",
    "    \n",
    "def deconv3D(name, l_input, out_shape, kernel_size, strides=[1,1,1,1,1], padding='SAME', with_w=True):\n",
    "    # output shape : (b, temporal depth, w, h, out_ch)\n",
    "    # filters : output_chnnel size\n",
    "    # kernel_size : size of kernel [kernel_temporal, filter_w, filter_h, out_ch, in_ch]\n",
    "    # strides : size of kernel [temporal, spatio_w, spatio_h, out_ch, in_ch]\n",
    "    # tf.nn.conv3d_transpose(input, filter=get_conv_weight\n",
    "    deconv_w=get_conv_weight(name=name+'_deconv3d', kshape=kernel_size)\n",
    "    print(\" >>deconv. l_input\", l_input)\n",
    "    print(\" >>deconv. deconv_w\", deconv_w)\n",
    "    deconv = tf.nn.conv3d_transpose(l_input, filter=deconv_w, output_shape=out_shape,\n",
    "                                    strides=strides, padding=padding, name=name+'_deconv')\n",
    "    \n",
    "    if with_w:\n",
    "        return deconv, deconv_w\n",
    "    else:\n",
    "        return deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class P3DBottleNeck():\n",
    "    def __init__(self, l_input, in_channels, channels, out_channels, n_t=3, downsample=False, _id=0, pType=\"A\", activation=True):\n",
    "        self.X = l_input\n",
    "        self.in_channels = in_channels\n",
    "        self.channels = channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_t = n_t\n",
    "        self.pType = pType\n",
    "        self.id = _id\n",
    "        self.downsample = downsample\n",
    "        if downsample:\n",
    "            self.strides=[1,1,2,2,1]\n",
    "        else:\n",
    "            self.strides=[1,1,1,1,1]\n",
    "        self.activation=activation\n",
    "    \n",
    "    def P3D_A(self, name, x, with_w=True):\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        if with_w:\n",
    "            x, w, b=convS(name+'_S', x, self.channels, self.channels, with_w=with_w)\n",
    "            w_list.append(w)\n",
    "            b_list.append(b)\n",
    "        else:\n",
    "            x=convS(name+'_S', x, self.channels, self.channels, with_w=with_w)\n",
    "        x=tf.layers.batch_normalization(x, training=IS_TRAIN)\n",
    "        x=tf.nn.relu(x)\n",
    "        \n",
    "        if with_w:\n",
    "            x, w, b=convT(name+'_T', x, self.channels, self.channels, n_t=self.n_t, with_w=with_w)\n",
    "            w_list.append(w)\n",
    "            b_list.append(b)\n",
    "        else:\n",
    "            x=convT(name+'_T', x, self.channels, self.channels, n_t=self.n_t, with_w=with_w)\n",
    "        x=tf.layers.batch_normalization(x, training=IS_TRAIN)\n",
    "        x=tf.nn.relu(x)\n",
    "        \n",
    "        if with_w:\n",
    "            return x, w_list, b_list\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def P3D_B(self, name, x, with_w=True):\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        if with_w:\n",
    "            x_s, w, b=convS(name+'_S', x, self.channels, self.channels, with_w=with_w)\n",
    "            w_list.append(w)\n",
    "            b_list.append(b)\n",
    "        else:\n",
    "            x_s=convS(name+'_S', x, self.channels, self.channels, with_w=with_w)\n",
    "        x_s=tf.layers.batch_normalization(x_s, training=IS_TRAIN)\n",
    "        x_s=tf.nn.relu(x_s)\n",
    "        \n",
    "        if with_w:\n",
    "            x_t, w, b=convT(name+'_T', x, self.channels, self.channels, n_t=self.n_t, with_w=with_w)\n",
    "            w_list.append(w)\n",
    "            b_list.append(b)\n",
    "        else:\n",
    "            x_t=convT(name+'_T', x, self.channels, self.channels, n_t=self.n_t, with_w=with_w)\n",
    "        x_t=tf.layers.batch_normalization(x_t, training=IS_TRAIN)\n",
    "        x_t=tf.nn.relu(x_s)\n",
    "        \n",
    "        if with_w:\n",
    "            return x_s + x_t, w_list, b_list\n",
    "        else:\n",
    "            return x_s + x_t\n",
    "    \n",
    "    def P3D_C(self, name, x, with_w=True):\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        if with_w:\n",
    "            x_s, w, b=convS(name+'_S', x, self.channels, self.channels, with_w=with_w)\n",
    "            w_list.append(w)\n",
    "            b_list.append(b)\n",
    "        else:\n",
    "            x_s=convS(name+'_S', x, self.channels, self.channels, with_w=with_w)\n",
    "        x_s=tf.layers.batch_normalization(x_s, training=IS_TRAIN)\n",
    "        x_s=tf.nn.relu(x_s)\n",
    "        \n",
    "        if with_w:\n",
    "            x_st, w, b=convT(name+'_T', x_s, self.channels, self.channels, n_t=self.n_t, with_w=with_w)\n",
    "            w_list.append(w)\n",
    "            b_list.append(b)\n",
    "        else:\n",
    "            x_st=convT(name+'_T', x_s, self.channels, self.channels, n_t=self.n_t, with_w=with_w)\n",
    "        x_st=tf.layers.batch_normalization(x_st, training=IS_TRAIN)\n",
    "        x_st=tf.nn.relu(x_st)\n",
    "        \n",
    "        if with_w:\n",
    "            return x_s + x_st, w_list, b_list\n",
    "        else:\n",
    "            return x_s + x_st\n",
    "    \n",
    "    def build(self, with_w=True):\n",
    "        residual = self.X\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        \n",
    "        # 1x1x1 conv : in_channels --> channels\n",
    "        conv_w=get_conv_weight('conv_1w_{}'.format(self.id), [1, 1, 1, self.in_channels, self.channels])\n",
    "        bias_w=get_conv_weight('conv_1b_{}'.format(self.id), [self.channels])\n",
    "        out=tf.nn.conv3d(self.X, conv_w, strides=self.strides, padding='SAME')\n",
    "        out=tf.nn.bias_add(out, bias_w, name='conv_1_{}'.format(self.id))\n",
    "        out=tf.layers.batch_normalization(out, training=IS_TRAIN)\n",
    "        out=tf.nn.relu(out)\n",
    "        \n",
    "        w_list.append(conv_w)\n",
    "        b_list.append(bias_w)\n",
    "        \n",
    "        # P3D : channels --> channels\n",
    "        if self.pType == \"A\":\n",
    "            out=self.P3D_A(name=\"P3D_A_{}\".format(self.id), x=out, with_w=with_w)\n",
    "        elif self.pType == \"B\":\n",
    "            out=self.P3D_B(name=\"P3D_B_{}\".format(self.id), x=out, with_w=with_w)\n",
    "        else:\n",
    "            out=self.P3D_C(name=\"P3D_C_{}\".format(self.id), x=out, with_w=with_w)\n",
    "       \n",
    "        if with_w:\n",
    "                w_list += out[1]\n",
    "                b_list += out[2]\n",
    "                out=out[0]\n",
    "                \n",
    "        # Residual\n",
    "        # 1x1x1 conv : channels --> out_channels\n",
    "        conv_w=get_conv_weight('conv_2w_{}'.format(self.id), [1, 1, 1, self.channels, self.out_channels])\n",
    "        bias_w=get_conv_weight('conv_2b_{}'.format(self.id), [self.out_channels])\n",
    "        out=tf.nn.conv3d(out, conv_w, strides=[1,1,1,1,1], padding='SAME')\n",
    "        out=tf.nn.bias_add(out, bias_w, name='conv_2_{}'.format(self.id))\n",
    "        out=tf.layers.batch_normalization(out, training=IS_TRAIN)\n",
    "        #out=tf.nn.relu(out)\n",
    "        \n",
    "        w_list.append(conv_w)\n",
    "        b_list.append(bias_w)\n",
    "        \n",
    "        # down-sampling residual : in_channels --> out_chaneels\n",
    "        conv_w=get_conv_weight('dw3d_w_{}'.format(self.id), [1, 1, 1, self.in_channels, self.out_channels])\n",
    "        bias_w=get_conv_weight('dw3d_b_{}'.format(self.id), [self.out_channels])\n",
    "        residual=tf.nn.conv3d(residual, conv_w, strides=self.strides, padding='SAME')\n",
    "        residual=tf.nn.bias_add(residual, bias_w, name='dw3d_{}'.format(self.id))\n",
    "        residual=tf.layers.batch_normalization(residual, training=IS_TRAIN)\n",
    "        \n",
    "        w_list.append(conv_w)\n",
    "        b_list.append(bias_w)\n",
    "        \n",
    "        if self.activation:    \n",
    "            out += residual\n",
    "            out = tf.nn.relu(out, name=\"{}_btn_P3D_{}\".format(self.id, self.pType))\n",
    "        else:\n",
    "            out = tf.add(out, residual, name=\"{}_btn_P3D_{}\".format(self.id, self.pType))\n",
    "        \n",
    "        if with_w:\n",
    "            return out, w_list, b_list\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class buildP3DBlock():\n",
    "    def __init__(self, l_input, in_channels, channels, out_channels, iteration, cnt,\n",
    "                 n_t=3, downsample=False, last_activation=True):\n",
    "        self.input = l_input\n",
    "        self.in_ch = in_channels\n",
    "        self.ch = channels\n",
    "        self.out_ch = out_channels\n",
    "        self.iteration = iteration\n",
    "        self.cnt = cnt\n",
    "        self.n_t = n_t\n",
    "        self.ptype = [\"A\", \"B\", \"C\"]\n",
    "        self.last_activation = last_activation\n",
    "        self.downsample=downsample\n",
    "    \n",
    "    def build(self, with_w=True):\n",
    "        len_ptype=len(self.ptype)\n",
    "        \n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        \n",
    "        ptype=self.ptype[self.cnt%len_ptype]\n",
    "        x = P3DBottleNeck(l_input=self.input,\n",
    "                          in_channels=self.in_ch, \n",
    "                          channels=self.ch, \n",
    "                          out_channels=self.out_ch,\n",
    "                          n_t=self.n_t,\n",
    "                          _id=self.cnt, \n",
    "                          downsample=self.downsample,\n",
    "                          pType=ptype).build(with_w=with_w)\n",
    "        if with_w:\n",
    "            w_list += x[1]\n",
    "            b_list += x[2]\n",
    "            x=x[0]\n",
    "        print(x)\n",
    "        \n",
    "        last_iter = self.cnt + self.iteration - 1\n",
    "        for i in range(self.cnt + 1, self.cnt + self.iteration):\n",
    "            ptype=self.ptype[i%len_ptype]\n",
    "            if i < last_iter:\n",
    "                x = P3DBottleNeck(l_input=x, \n",
    "                                  in_channels=self.out_ch, \n",
    "                                  channels=self.ch, \n",
    "                                  out_channels=self.out_ch, \n",
    "                                  n_t=self.n_t,\n",
    "                                  _id=i, \n",
    "                                  pType=ptype).build(with_w=with_w)\n",
    "            else:\n",
    "                x = P3DBottleNeck(l_input=x, \n",
    "                                  in_channels=self.out_ch, \n",
    "                                  channels=self.ch, \n",
    "                                  out_channels=self.out_ch, \n",
    "                                  n_t=self.n_t,\n",
    "                                  _id=i, \n",
    "                                  pType=ptype,\n",
    "                                  activation=self.last_activation).build(with_w=with_w)\n",
    "\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "            print(x)\n",
    "        \n",
    "        if with_w:\n",
    "            return x, w_list, b_list\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AAE():\n",
    "    def __init__(self, img_ch=1, n_t=2): \n",
    "        '''\n",
    "          Parameters\n",
    "             x   : input tensor\n",
    "             n_t : step size of temporal direction (used in P3D, convT())\n",
    "        '''\n",
    "        #self.x = x\n",
    "        self.n_t = n_t\n",
    "        self.img_ch = img_ch\n",
    "        \n",
    "        #self.input_shape = self.x.get_shape().as_list()\n",
    "    \n",
    "    def encoder(self, _x, with_w=True):\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        with tf.variable_scope(\"Encoder\", reuse=tf.AUTO_REUSE):    \n",
    "            cnt=0\n",
    "            # _x: [batch, t, h, w, 3]\n",
    "            # x: [batch, t, h, w, 32]\n",
    "            conv_w=get_conv_weight('AAE_E_conv1_w', [1, 3, 3, self.img_ch, 32])\n",
    "            bias_w=get_conv_weight('AAE_E_conv1_b', [32])\n",
    "            x=tf.nn.conv3d(_x, conv_w, strides=[1,1,1,1,1], padding='SAME')\n",
    "            x=tf.nn.bias_add(x, bias_w, name='AAE_E_conv1')\n",
    "            x=tf.layers.batch_normalization(x, training=IS_TRAIN)\n",
    "            x=tf.nn.relu(x)\n",
    "            \n",
    "            w_list.append(conv_w)\n",
    "            b_list.append(bias_w)\n",
    "            print(x)\n",
    "\n",
    "            # x: [batch, t, h, w, 32]\n",
    "            iteration=3\n",
    "            x=buildP3DBlock(x, 32, 16, 32, iteration=iteration, cnt=cnt, n_t=self.n_t).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "                print(\"with_w: \", with_w)\n",
    "\n",
    "            # x: [batch, t/2, h/2, w/2, 32]\n",
    "            x= tf.nn.max_pool3d(x, [1, 3, 3, 3, 1], strides=[1, self.n_t, 2, 2, 1], padding='SAME')\n",
    "\n",
    "            # x: [batch, t/2, h/2, w/2, 64]\n",
    "            iteration=5\n",
    "            x=buildP3DBlock(x, 32, 16, 64, iteration=iteration, cnt=cnt, n_t=self.n_t).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "\n",
    "            # x: [batch, t/4, h/4, w/4, 64]\n",
    "            x= tf.nn.max_pool3d(x, [1, 3, 1, 1, 1], strides=[1, self.n_t, 2, 2, 1], padding='SAME')\n",
    "\n",
    "            # x: [batch, t/4, h/4, w/4, 64]\n",
    "            iteration=5\n",
    "            x=buildP3DBlock(x, 64, 32, 64, iteration=iteration, cnt=cnt, n_t=self.n_t).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "\n",
    "            # x: [batch, t/8, h/4, w/4, 64]\n",
    "            x= tf.nn.max_pool3d(x, [1, 3, 3, 3, 1], strides=[1, self.n_t, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            # x: [batch, t/8, h/4, w/4, 128]\n",
    "            iteration=8\n",
    "            x=buildP3DBlock(x, 64, 32, 128, iteration=iteration, cnt=cnt, n_t=self.n_t, \n",
    "                         last_activation=False).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "            \n",
    "            conv_w=get_conv_weight('AAE_E_conv2_w', [1, 3, 3, 128, 128])\n",
    "            bias_w=get_conv_weight('AAE_E_conv2_b', [128])\n",
    "            x=tf.nn.conv3d(x, conv_w, strides=[1,1,1,1,1], padding='SAME')\n",
    "            x=tf.nn.bias_add(x, bias_w, name='AAE_E_conv2')\n",
    "\n",
    "            w_list.append(conv_w)\n",
    "            b_list.append(bias_w)\n",
    "            \n",
    "        if with_w:\n",
    "            return x, w_list, b_list\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def decoder(self, _x, with_w=True):\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        \n",
    "        with tf.variable_scope(\"Decoder\", reuse=tf.AUTO_REUSE):\n",
    "            cnt=21\n",
    "            # _x: [batch, t/8, h/4, w/4, 128]\n",
    "            iteration=8\n",
    "            x=buildP3DBlock(_x, 128, 32, 64, iteration=iteration, cnt=cnt, n_t=self.n_t).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "\n",
    "            # x: [batch, t/4, h/4, w/4, 64]\n",
    "            o_size=x.get_shape().as_list()  # [b, t, h, w, c]\n",
    "            print(\" >> x: \", x)\n",
    "            #x=deconv3D(\"AAE_D_deconv1\", x, [o_size[0], o_size[1]*self.n_t, o_size[2], o_size[3], o_size[4]], [self.n_t, 3, 3, 64, 64], with_w=with_w)\n",
    "            x=deconv3D(\"AAE_D_deconv1\", x, [o_size[0], o_size[1]*self.n_t, o_size[2], o_size[3], o_size[4]], [2, 3, 3, 64, 64], with_w=with_w)\n",
    "            if with_w:\n",
    "                w_list.append(x[1])\n",
    "                x=x[0]\n",
    "                \n",
    "            # x: [batch, t/4, h/4, w/4, 64]\n",
    "            iteration=5\n",
    "            x=buildP3DBlock(x, 64, 32, 64, iteration=iteration, cnt=cnt, n_t=self.n_t).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "\n",
    "            # x: [batch, t/2, h/2, w/2, 64]\n",
    "            o_size=x.get_shape().as_list()  # [b, t, h, w, c]\n",
    "            x=deconv3D(\"AAE_D_deconv2\", x, [o_size[0], o_size[1]*self.n_t, o_size[2]*2, o_size[3]*2, o_size[4]], [self.n_t, 3, 3, 64, 64], with_w=with_w)\n",
    "            #print(x)\n",
    "            if with_w:\n",
    "                w_list.append(x[1])\n",
    "                x=x[0]\n",
    "            \n",
    "            # x: [batch, t/2, h/2, w/2, 32]\n",
    "            iteration=5\n",
    "            x=buildP3DBlock(x, 64, 16, 32, iteration=iteration, cnt=cnt, n_t=self.n_t).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "\n",
    "            # x: [batch, t, h, w, 32]\n",
    "            o_size=x.get_shape().as_list()  # [b, t, h, w, c]\n",
    "            x=deconv3D(\"AAE_D_deconv3\", x, [o_size[0], o_size[1]*self.n_t, o_size[2]*2, o_size[3]*2, o_size[4]], [self.n_t, 3, 3, 32, 32], with_w=with_w)\n",
    "            #print(x)\n",
    "            if with_w:\n",
    "                w_list.append(x[1])\n",
    "                x=x[0]\n",
    "            \n",
    "            # x: [batch, t, h, w, 32]\n",
    "            iteration=3\n",
    "            x=buildP3DBlock(x, 32, 16, 32, iteration=iteration, cnt=cnt, n_t=self.n_t).build(with_w=with_w)\n",
    "            cnt += iteration\n",
    "            if with_w:\n",
    "                w_list += x[1]\n",
    "                b_list += x[2]\n",
    "                x=x[0]\n",
    "\n",
    "            # x: [batch, t, h, w, 3]\n",
    "            conv_w=get_conv_weight('AAE_D_conv_w', [1, 3, 3, 32, self.img_ch])\n",
    "            bias_w=get_conv_weight('AAE_D_conv_b', [self.img_ch])\n",
    "            x=tf.nn.conv3d(x, conv_w, strides=[1,1,1,1,1], padding='SAME')\n",
    "            x=tf.nn.bias_add(x, bias_w, name='AAE_D_conv')\n",
    "            x=tf.layers.batch_normalization(x, training=IS_TRAIN)\n",
    "            x=tf.nn.sigmoid(x, name='AAE_D_x_hat')\n",
    "\n",
    "            w_list.append(conv_w)\n",
    "            b_list.append(bias_w)\n",
    "            \n",
    "        if with_w:\n",
    "            return x, w_list, b_list\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def discriminator(self, z, with_w=True):\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        \n",
    "        with tf.variable_scope(\"Discriminator\", reuse=tf.AUTO_REUSE):\n",
    "            # z : [batchsize, t, h, w, c]   ... [none, 1, 40, 40, 128]\n",
    "            conv_w=get_conv_weight('AAE_Disc_conv1_w', [1, 3, 3, z.get_shape().as_list()[-1], 64])\n",
    "            bias_w=get_conv_weight('AAE_Disc_conv1_b', [64])\n",
    "            h1 =tf.nn.conv3d(z, conv_w, strides=[1,1,2,2,1], padding='SAME')\n",
    "            h1 =tf.nn.bias_add(h1, bias_w, name='AAE_Disc_conv1')\n",
    "            h1 =tf.layers.batch_normalization(h1, training=IS_TRAIN)\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            \n",
    "            w_list.append(conv_w)\n",
    "            b_list.append(bias_w)\n",
    "            \n",
    "            # [None, 1, 20, 20, 32]\n",
    "            conv_w=get_conv_weight('AAE_Disc_conv2_w', [1, 1, 1, 64, 32])\n",
    "            bias_w=get_conv_weight('AAE_Disc_conv2_b', [32])\n",
    "            h2 =tf.nn.conv3d(h1, conv_w, strides=[1,1,1,1,1], padding='SAME')\n",
    "            h2 =tf.nn.bias_add(h2, bias_w, name='AAE_Disc_conv2')\n",
    "            h2 =tf.layers.batch_normalization(h2, training=IS_TRAIN)\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            \n",
    "            w_list.append(conv_w)\n",
    "            b_list.append(bias_w)\n",
    "            \n",
    "            # [None, 1, 20, 20, 1]\n",
    "            logits = conv3d(\"AAE_Disc_logits\", h2, [1, 1, 1, 32, 1], strides=[1, 1, 1, 1, 1], with_w=with_w)\n",
    "            \n",
    "            if with_w:\n",
    "                w_list.append(logits[1])\n",
    "                b_list.append(logits[2])\n",
    "                logits=logits[0]\n",
    "        \n",
    "        if with_w:\n",
    "            return tf.nn.sigmoid(logits), logits, w_list, b_list\n",
    "        else:\n",
    "            return tf.nn.sigmoid(logits), logits\n",
    "    \n",
    "    def autoencoder(self, _x, z_sample, with_w=True):\n",
    "        w_list=[]\n",
    "        b_list=[]\n",
    "        \n",
    "        # encoding\n",
    "        z = self.encoder(_x, with_w=with_w)\n",
    "        if with_w:\n",
    "            w_list += z[1]\n",
    "            b_list += z[2]\n",
    "            z = z[0]\n",
    "        print(z)\n",
    "        # decoding\n",
    "        y = self.decoder(z)\n",
    "        if with_w:\n",
    "            w_list += y[1]\n",
    "            b_list += y[2]\n",
    "            y = y[0]\n",
    "        \n",
    "        # Reconstruction Loss\n",
    "        marginal_likelihood = -tf.reduce_mean(tf.reduce_mean(tf.squared_difference(_x, y)))\n",
    "        \n",
    "        # GAN Loss\n",
    "        z_real = z_sample\n",
    "        z_fake = z\n",
    "        \n",
    "        if with_w:\n",
    "            D_real, D_real_logits, w_list_r, b_list_r = self.discriminator(z_real, with_w=with_w)\n",
    "            D_fake, D_fake_logits, w_list_f, b_list_f = self.discriminator(z_fake, with_w=with_w)\n",
    "            w_list += w_list_r\n",
    "            b_list += b_list_r\n",
    "            w_list += w_list_f\n",
    "            b_list += b_list_f\n",
    "        else:\n",
    "            D_real, D_real_logits = self.discriminator(z_real, with_w=with_w)\n",
    "            D_fake, D_fake_logits = self.discriminator(z_fake, with_w=with_w)\n",
    "        \n",
    "        # Discriminator Loss\n",
    "        D_loss_real = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real_logits)))\n",
    "        D_loss_fake = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake_logits)))\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "        \n",
    "        # Generator Loss\n",
    "        G_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake_logits)))\n",
    "        \n",
    "        marginal_likelihood = tf.reduce_mean(marginal_likelihood)\n",
    "        D_loss = tf.reduce_mean(D_loss)\n",
    "        G_loss = tf.reduce_mean(G_loss)\n",
    "        \n",
    "        if with_w:\n",
    "            return y, z, -marginal_likelihood, D_loss, G_loss, w_list, b_list\n",
    "        else:\n",
    "            return y, z, -marginal_likelihood, D_loss, G_loss\n",
    "        \n",
    "    def autoencoder_tmp(self, _x):\n",
    "        enc = self.encoder(_x)\n",
    "        \n",
    "        mu, log_std_sq = tf.split(enc, 2, -1)\n",
    "        \n",
    "        eps = tf.random_normal(tf.shape(mu), 0, 1, dtype=tf.float32)\n",
    "        #z = tf.add(mu, tf.matmul(tf.sqrt(tf.exp(log_std_sq)), eps))\n",
    "        z = tf.add(mu, tf.sqrt(tf.exp(log_std_sq)) * eps)\n",
    "        print(\"Enc: \", enc)\n",
    "        print(\"z. : \", z)\n",
    "        x_hat = self.decoder(z)\n",
    "        x_hat = tf.clip_by_value(x_hat, 1e-8, 1 - 1e-8)\n",
    "\n",
    "        # Loss\n",
    "        marginal_likelihood = tf.reduce_sum(_x * tf.log(x_hat) + (1 - _x) * tf.log(1 - x_hat), -1)\n",
    "        marginal_likelihood = tf.reduce_mean(marginal_likelihood)\n",
    "\n",
    "        KL_divergence = 0.5 * tf.reduce_sum(tf.square(mu) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1, 1)\n",
    "\n",
    "        \n",
    "        KL_divergence = 0.5 * tf.reduce_sum(tf.square(mu) + tf.exp(1e-8 + log_std_sq) - log_std_sq - 1, -1)\n",
    "        KL_divergence = tf.reduce_mean(KL_divergence)\n",
    "        \n",
    "        ELBO = marginal_likelihood - KL_divergence\n",
    "        \n",
    "        loss = -ELBO\n",
    "        return x_hat, z, enc, loss, -marginal_likelihood, KL_divergence\n",
    "        \n",
    "        \n",
    "    def generate_sample(self, _x):\n",
    "        z=self.encoder(_x)\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def build(self, _x):\n",
    "        1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Build Graph'''\n",
    "# input placeholder\n",
    "x = tf.placeholder(tf.float32, shape=[None, 8, 224, 224, 1])\n",
    "z_sample = tf.placeholder(tf.float32, shape=[None, 1, 224//4, 224//4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Network Architecture'''\n",
    "model = AAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Encoder_4/Relu:0\", shape=(?, 8, 224, 224, 32), dtype=float32)\n",
      "Tensor(\"Encoder_4/0_btn_P3D_A:0\", shape=(?, 8, 224, 224, 32), dtype=float32)\n",
      "Tensor(\"Encoder_4/1_btn_P3D_B:0\", shape=(?, 8, 224, 224, 32), dtype=float32)\n",
      "Tensor(\"Encoder_4/2_btn_P3D_C:0\", shape=(?, 8, 224, 224, 32), dtype=float32)\n",
      "with_w:  True\n",
      "Tensor(\"Encoder_4/3_btn_P3D_A:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/4_btn_P3D_B:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/5_btn_P3D_C:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/6_btn_P3D_A:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/7_btn_P3D_B:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/8_btn_P3D_C:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/9_btn_P3D_A:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/10_btn_P3D_B:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/11_btn_P3D_C:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/12_btn_P3D_A:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder_4/13_btn_P3D_B:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder_4/14_btn_P3D_C:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder_4/15_btn_P3D_A:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder_4/16_btn_P3D_B:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder_4/17_btn_P3D_C:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder_4/18_btn_P3D_A:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder_4/19_btn_P3D_B:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder_4/20_btn_P3D_C:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# encoding\n",
    "z = model.encoder(x, with_w=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Encoder/AAE_E_conv1_w:0' shape=(1, 3, 3, 1, 32) dtype=float32_ref>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Encoder_3/AAE_E_conv2:0' shape=(?, 1, 56, 56, 128) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>deconv. l_input Tensor(\"Encoder_3/AAE_E_conv2:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      " >>deconv. deconv_w <tf.Variable 'test_deconv2_deconv3d:0' shape=(2, 3, 3, 128, 128) dtype=float32_ref>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 2, 112, 112, 128]. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got None",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-732a6b793393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeconv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_deconv2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m56\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m56\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-aaa3029d92a1>\u001b[0m in \u001b[0;36mdeconv3D\u001b[0;34m(name, l_input, out_shape, kernel_size, strides, padding, with_w)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" >>deconv. deconv_w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeconv_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     deconv = tf.nn.conv3d_transpose(l_input, filter=deconv_w, output_shape=out_shape,\n\u001b[0;32m---> 62\u001b[0;31m                                     strides=strides, padding=padding, name=name+'_deconv')\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv3d_transpose\u001b[0;34m(value, filter, output_shape, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1404\u001b[0m                                          filter.get_shape()[4]))\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m     \u001b[0moutput_shape_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput_shape_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m       raise ValueError(\"output_shape must have shape (5,), got {}\"\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    470\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    471\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 2, 112, 112, 128]. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "deconv3D(\"test_deconv2\", z, [None, 2, 56*2, 56*2, 128], [2, 3, 3, 128, 128], with_w=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>deconv. l_input Tensor(\"Encoder_4/AAE_E_conv2:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      " >>deconv. deconv_w <tf.Variable 'test_deconv7_deconv3d:0' shape=(2, 3, 3, 128, 128) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'test_deconv7_deconv:0' shape=(1, 2, 112, 112, 128) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv3D2(\"test_deconv7\", z[0], [1, 2, 56*2, 56*2, 128], [2, 3, 3, 128, 128], with_w=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_weight2(name,kshape,wd=0.0005):\n",
    "    #with tf.device('/cpu:0'):\n",
    "    var=tf.get_variable(name, dtype=tf.float32, shape=kshape,initializer=tf.contrib.layers.xavier_initializer())\n",
    "    if wd!=0:\n",
    "        weight_decay = tf.nn.l2_loss(var)*wd\n",
    "        tf.add_to_collection('weightdecay_losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv3D2(name, l_input, out_shape, kernel_size, strides=[1,1,1,1,1], padding='SAME', with_w=True):\n",
    "    # output shape : (b, temporal depth, w, h, out_ch)\n",
    "    # filters : output_chnnel size\n",
    "    # kernel_size : size of kernel [kernel_temporal, filter_w, filter_h, out_ch, in_ch]\n",
    "    # strides : size of kernel [temporal, spatio_w, spatio_h, out_ch, in_ch]\n",
    "    # tf.nn.conv3d_transpose(input, filter=get_conv_weight\n",
    "    deconv_w=get_conv_weight2(name=name+'_deconv3d', kshape=kernel_size)\n",
    "    print(\" >>deconv. l_input\", l_input)\n",
    "    print(\" >>deconv. deconv_w\", deconv_w)\n",
    "    deconv = tf.nn.conv3d_transpose(l_input, filter=deconv_w, output_shape=out_shape,\n",
    "                                    strides=strides, padding=padding, name=name+'_deconv')\n",
    "    \n",
    "    if with_w:\n",
    "        return deconv, deconv_w\n",
    "    else:\n",
    "        return deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Decoder_1/21_btn_P3D_A:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder_1/22_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder_1/23_btn_P3D_C:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder_1/24_btn_P3D_A:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder_1/25_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder_1/26_btn_P3D_C:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder_1/27_btn_P3D_A:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder_1/28_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      " >> x:  Tensor(\"Decoder_1/28_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trying to share variable Decoder/AAE_D_deconv1_deconv3d, but specified shape (2, 3, 3, 64, 64) and found shape (1, 3, 3, 64, 64).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b9e89cdaa648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-9082fdfd4d52>\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(self, _x, with_w)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" >> x: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m#x=deconv3D(\"AAE_D_deconv1\", x, [o_size[0], o_size[1]*self.n_t, o_size[2], o_size[3], o_size[4]], [self.n_t, 3, 3, 64, 64], with_w=with_w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeconv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AAE_D_deconv1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aaa3029d92a1>\u001b[0m in \u001b[0;36mdeconv3D\u001b[0;34m(name, l_input, out_shape, kernel_size, strides, padding, with_w)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# strides : size of kernel [temporal, spatio_w, spatio_h, out_ch, in_ch]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# tf.nn.conv3d_transpose(input, filter=get_conv_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mdeconv_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_conv_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_deconv3d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" >>deconv. l_input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" >>deconv. deconv_w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeconv_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aaa3029d92a1>\u001b[0m in \u001b[0;36mget_conv_weight\u001b[0;34m(name, kshape, wd)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_conv_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#with tf.device('/cpu:0'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1205\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    745\u001b[0m         raise ValueError(\"Trying to share variable %s, but specified shape %s\"\n\u001b[1;32m    746\u001b[0m                          \" and found shape %s.\" % (name, shape,\n\u001b[0;32m--> 747\u001b[0;31m                                                    found_var.get_shape()))\n\u001b[0m\u001b[1;32m    748\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mdtype_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Trying to share variable Decoder/AAE_D_deconv1_deconv3d, but specified shape (2, 3, 3, 64, 64) and found shape (1, 3, 3, 64, 64)."
     ]
    }
   ],
   "source": [
    "y = model.decoder(z, with_w=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.AUTO_REUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Encoder/0_btn_P3D_A:0\", shape=(?, 8, 224, 224, 32), dtype=float32)\n",
      "Tensor(\"Encoder/1_btn_P3D_B:0\", shape=(?, 8, 224, 224, 32), dtype=float32)\n",
      "Tensor(\"Encoder/2_btn_P3D_C:0\", shape=(?, 8, 224, 224, 32), dtype=float32)\n",
      "Tensor(\"Encoder/3_btn_P3D_A:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder/4_btn_P3D_B:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder/5_btn_P3D_C:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder/6_btn_P3D_A:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder/7_btn_P3D_B:0\", shape=(?, 4, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Encoder/8_btn_P3D_C:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder/9_btn_P3D_A:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder/10_btn_P3D_B:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder/11_btn_P3D_C:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder/12_btn_P3D_A:0\", shape=(?, 2, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Encoder/13_btn_P3D_B:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/14_btn_P3D_C:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/15_btn_P3D_A:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/16_btn_P3D_B:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/17_btn_P3D_C:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/18_btn_P3D_A:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/19_btn_P3D_B:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/20_btn_P3D_C:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Encoder/AAE_E_conv2:0\", shape=(?, 1, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Decoder/21_btn_P3D_A:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder/22_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder/23_btn_P3D_C:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder/24_btn_P3D_A:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder/25_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder/26_btn_P3D_C:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder/27_btn_P3D_A:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Decoder/28_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      " >> x:  Tensor(\"Decoder/28_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      " >>deconv. l_input Tensor(\"Decoder/28_btn_P3D_B:0\", shape=(?, 1, 56, 56, 64), dtype=float32)\n",
      " >>deconv. deconv_w <tf.Variable 'Decoder/AAE_D_deconv1_deconv3d:0' shape=(1, 3, 3, 64, 64) dtype=float32_ref>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 2, 56, 56, 64]. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got None",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2d7d53ae3d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarginal_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-1b5cc5ad74f8>\u001b[0m in \u001b[0;36mautoencoder\u001b[0;34m(self, _x, z_sample, with_w)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# decoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mw_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1b5cc5ad74f8>\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(self, _x, with_w)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" >> x: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m#x=deconv3D(\"AAE_D_deconv1\", x, [o_size[0], o_size[1]*self.n_t, o_size[2], o_size[3], o_size[4]], [self.n_t, 3, 3, 64, 64], with_w=with_w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeconv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AAE_D_deconv1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aaa3029d92a1>\u001b[0m in \u001b[0;36mdeconv3D\u001b[0;34m(name, l_input, out_shape, kernel_size, strides, padding, with_w)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" >>deconv. deconv_w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeconv_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     deconv = tf.nn.conv3d_transpose(l_input, filter=deconv_w, output_shape=out_shape,\n\u001b[0;32m---> 62\u001b[0;31m                                     strides=strides, padding=padding, name=name+'_deconv')\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwith_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv3d_transpose\u001b[0;34m(value, filter, output_shape, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1404\u001b[0m                                          filter.get_shape()[4]))\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m     \u001b[0moutput_shape_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput_shape_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m       raise ValueError(\"output_shape must have shape (5,), got {}\"\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/py36tf1x/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    470\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    471\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 2, 56, 56, 64]. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "y, z, marginal_likelihood, D_loss, G_loss, w_list, b_list = model.autoencoder(x, z_sample, with_w=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36tf1x",
   "language": "python",
   "name": "py36tf1x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
