{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해야할 일\n",
    "### 0. z_sample Generate 하는 방법과 사용방법이 현재가 맞는지 확인할 필요가 있음.\n",
    "### 1. Session 저장하고 불러오는 기능\n",
    "### 2. 시각화 (Reconstruction, Latent)\n",
    "### 3. Summary for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsu/py36tf1x/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from config import *\n",
    "import dbread as db\n",
    "from AAE import AAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_frames_per_clip = 8\n",
    "IMAGE_CROP_SIZE=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dataset Reader'''\n",
    "reader=db.DBreader(batch_size=batch_size, n_frames_clip=num_frames_per_clip, \n",
    "                   resize=[IMAGE_CROP_SIZE, IMAGE_CROP_SIZE], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(images, resize_factor=1.0, direction=\"V\"):\n",
    "    try:\n",
    "        assert direction in [\"H\", \"V\"]\n",
    "    except:\n",
    "        print(\"direction must be 'V' or 'H'. If not, default is 'H'\")\n",
    "    \n",
    "    # images: [b, d, h, w, c]\n",
    "    batch_size=images.shape[0]\n",
    "    depth = images.shape[1]\n",
    "    if len(images.shape) == 5 and images.shape[4] == 1:\n",
    "        images=images[:,:,:,:,0]\n",
    "    h, w = images.shape[2], images.shape[3]\n",
    "\n",
    "    h_ = int(h * resize_factor)\n",
    "    w_ = int(w * resize_factor)\n",
    "\n",
    "    if direction == \"V\":\n",
    "        img = np.zeros((h_ * depth, w_ * batch_size))\n",
    "    else:\n",
    "        img = np.zeros((h_ * batch_size, w_ * depth))\n",
    "\n",
    "    if direction == \"V\":\n",
    "        for r in range(depth):\n",
    "            for c in range(batch_size):\n",
    "                image_ = imresize(images[c][r], size=(w_,h_), interp='bicubic')\n",
    "                img[r*h_:r*h_+h_, c*w_:c*w_+w_] = image_\n",
    "    else:\n",
    "        for r in range(batch_size):\n",
    "            for c in range(depth):\n",
    "                image_ = imresize(images[r][c], size=(w_,h_), interp='bicubic')\n",
    "                img[r*h_:r*h_+h_, c*w_:c*w_+w_] = image_\n",
    "\n",
    "    return img\n",
    "\n",
    "def save_images(self, images, name='result/result.jpg'):\n",
    "    imsave(name, merge_images(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CROP_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' parsing and configuration '''\n",
    "def parse_args():\n",
    "    desc=\"Implementation of AAE with P3D models using Tensorflow for Anomaly Detection in Video Scenes\"\n",
    "    parser = argparse.ArgumentParser(description=desc)\n",
    "    \n",
    "    parser.add_argument('--num_epochs', type=int, default=NUM_EPOCHS)\n",
    "    parser.add_argument('--initial_learning_rate', type=float, default=INITIAL_LEARNING_RATE)\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE)\n",
    "    parser.add_argument('--num_frames_per_clip', type=int, default=NUM_FRAMES_PER_CLIP)\n",
    "    parser.add_argument('--dataset_shuffle', type=bool, default=True)\n",
    "\n",
    "    parser.add_argument('--log_dir', type=str, default=LOG_DIR)\n",
    "    parser.add_argument('--model_dir', type=str, default=MODEL_DIR)\n",
    "    parser.add_argument('--result_dir', type=str, default=RESULT_DIR)\n",
    "    \n",
    "    parser.add_argument('--z_dim', type=int, default=LATENT_DIM)\n",
    "    parser.add_argument('--image_crop_size', type=int, default=IMAGE_CROP_SIZE)\n",
    "    \n",
    "    return check_args(parser.parse_args())\n",
    "\n",
    "''' checking arguments'''\n",
    "def check_args(args):\n",
    "    # --num_epochs\n",
    "    try:\n",
    "        assert args.num_epochs <= 0\n",
    "    except:\n",
    "        print(\"number of epochs must be larger than or equal to one\")\n",
    "    \n",
    "    # --initial_learning_rate\n",
    "    try:\n",
    "        assert args.initial_learning_rate > 0\n",
    "    except:\n",
    "        print(\"initial_learning_rate must be positive\")\n",
    "    \n",
    "    # --batch_size\n",
    "    try:\n",
    "        assert args.batch_size > 0\n",
    "    except:\n",
    "        print(\"batch size must be larger than or equal to one\")\n",
    "    \n",
    "    # --num_frames_per_clip\n",
    "    try:\n",
    "        assert args.num_frames_per_clip > 0\n",
    "    except:\n",
    "        print(\"number of frames per clip must be larger than or equal to one. (8 is recommanded)\")\n",
    "    \n",
    "    # --dataset_shuffle\n",
    "    try:\n",
    "        assert args.dataset_shuffle == True or args.dataset_shuffle == False\n",
    "    except:\n",
    "        print(\"dataset shuffle flag must be boolean type\")\n",
    "    \n",
    "    # --log_dir\n",
    "    try:\n",
    "        os.mkdir(args.log_dir)\n",
    "    except(FileExistsError):\n",
    "        pass\n",
    "    # delete all existing files\n",
    "    files = glob.glob(args.log_dir + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    \n",
    "    # --model_dir\n",
    "    try:\n",
    "        os.mkdir(args.model_dir)\n",
    "    except(FileExistsError):\n",
    "        pass\n",
    "    # delete all existing files\n",
    "    files = glob.glob(args.model_dir + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        \n",
    "    # --log_dir\n",
    "    try:\n",
    "        os.mkdir(args.result_dir)\n",
    "    except(FileExistsError):\n",
    "        pass\n",
    "    # delete all existing files\n",
    "    files = glob.glob(args.result_dir + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        \n",
    "    # --z_dim\n",
    "    try:\n",
    "        assert args.z_dim > 0\n",
    "    except:\n",
    "        print(\"z dimension(latent dimension) must be larger than or equal to one\")\n",
    "    \n",
    "    # --image_crop_size\n",
    "    try:\n",
    "        assert args.image_crop_size > 0\n",
    "    except:\n",
    "        print(\"image cropping size must be larger than or equal to one. (224 is recommanded)\")\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' parsing and configuration '''\n",
    "def parse_args2():\n",
    "    args={}\n",
    "    args[\"desc\"]=\"Implementation of AAE with P3D models using Tensorflow for Anomaly Detection in Video Scenes\"\n",
    "    args['num_epochs']=NUM_EPOCHS\n",
    "    args['initial_learning_rate']=INITIAL_LEARNING_RATE\n",
    "    args['batch_size']=BATCH_SIZE\n",
    "    args['num_frames_per_clip']=NUM_FRAMES_PER_CLIP\n",
    "    args['dataset_shuffle']=True\n",
    "    args['log_dir']=LOG_DIR\n",
    "    args['model_dir']=MODEL_DIR\n",
    "    args['result_dir']=RESULT_DIR\n",
    "    args['z_dim']=LATENT_DIM\n",
    "    \n",
    "    return args #check_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=parse_args2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatch_size = args.batch_size\\nnum_frames_per_clip = args.num_frames_per_clip\\ndataset_shuffle = args.dataset_shuffle\\n\\nnum_epochs = args.num_epochs\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = args['batch_size']\n",
    "num_frames_per_clip = args['num_frames_per_clip']\n",
    "dataset_shuffle = args['dataset_shuffle']\n",
    "num_epochs = args['num_epochs']\n",
    "initial_learning_rate = args['initial_learning_rate']\n",
    "z_dim = args['z_dim']\n",
    "\n",
    "\"\"\"\n",
    "batch_size = args.batch_size\n",
    "num_frames_per_clip = args.num_frames_per_clip\n",
    "dataset_shuffle = args.dataset_shuffle\n",
    "\n",
    "num_epochs = args.num_epochs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dataset Reader'''\n",
    "reader=db.DBreader(batch_size=batch_size, n_frames_clip=num_frames_per_clip, \n",
    "                   resize=[IMAGE_CROP_SIZE, IMAGE_CROP_SIZE], shuffle=dataset_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Build Graph'''\n",
    "# input placeholder\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, num_frames_per_clip, IMAGE_CROP_SIZE, IMAGE_CROP_SIZE, 1])\n",
    "z_sample = tf.placeholder(tf.float32, shape=[batch_size, 1, IMAGE_CROP_SIZE//4, IMAGE_CROP_SIZE//4, z_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Network Architecture'''\n",
    "model = AAE()\n",
    "\n",
    "y, z, neg_marginal_likelihood, D_loss, G_loss = model.adversarial_autoencoder(x, z_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Optimization '''\n",
    "t_vars = tf.trainable_variables()\n",
    "d_vars = [var for var in t_vars if \"Discriminator\" in var.name]\n",
    "g_vars = [var for var in t_vars if \"Encoder\" in var.name]\n",
    "ae_vars = [var for var in t_vars if \"Encoder\" or \"Decoder\" in var.name]\n",
    "\n",
    "train_op_ae = tf.train.AdamOptimizer(initial_learning_rate).minimize(neg_marginal_likelihood, var_list=ae_vars)\n",
    "train_op_d  = tf.train.AdamOptimizer(initial_learning_rate/5).minimize(D_loss, var_list=d_vars)\n",
    "train_op_g  = tf.train.AdamOptimizer(initial_learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kimsu/Desktop/kimsu/01_study/05_src/anomaly_detection/master'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsu/py36tf1x/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    }
   ],
   "source": [
    "m_images=merge_images(test_images, direction=\"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(m_images).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Initialized\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1ab7f4bd3554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtest_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#Image.fromarray(merge_images(test_images, direction=\"V\")).show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0msave_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/kimsu/Desktop/kimsu/01_study/05_src/anomaly_detection/master/result'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RECON_initial.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-85b6206cec21>\u001b[0m in \u001b[0;36msave_images\u001b[0;34m(self, images, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'result/result.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-85b6206cec21>\u001b[0m in \u001b[0;36mmerge_images\u001b[0;34m(images, resize_factor, direction)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# images: [b, d, h, w, c]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "''' Training '''\n",
    "total_batch = reader.n_train_clips // batch_size\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "model_name=\"model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Variable Initialized\")\n",
    "    \n",
    "    test_x = reader.next_batch(False)\n",
    "    test_x = test_x / 255.0\n",
    "\n",
    "    test_y = sess.run(y, feed_dict={x:test_x})\n",
    "\n",
    "    test_images=np.array([test_x, test_y])\n",
    "    #Image.fromarray(merge_images(test_images, direction=\"V\")).show()\n",
    "    save_images(test_images, os.path.join('/Users/kimsu/Desktop/kimsu/01_study/05_src/anomaly_detection/master/result', 'RECON_initial.png'))\n",
    "    \n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Train Dataset Random Shuffling\n",
    "        reader.initialize(True)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            train_x = reader.next_batch() / 255.\n",
    "\n",
    "            # now here, generate z_sample by random noise\n",
    "            # z_sample.shape.as_list()  --> sample's shape\n",
    "            # train_z_sample = np.random.random(z_sample.shape.as_list())\n",
    "            train_z_sample = np.random.normal(0, 1, z_sample.shape.as_list()).astype(np.float32)\n",
    "            \n",
    "            # Reconstruction Loss\n",
    "            _, loss_likelihood = sess.run([train_op_ae, neg_marginal_likelihood],\n",
    "                                         feed_dict={x:train_x, z_sample:train_z_sample})\n",
    "            \n",
    "            # Discriminator loss\n",
    "            _, d_loss = sess.run([train_op_d, D_loss],\n",
    "                                feed_dict={x:train_x, z_sample:train_z_sample})\n",
    "            \n",
    "            # Generator loss\n",
    "            for _ in range(2):\n",
    "                _, g_loss = sess.run([train_op_g, G_loss],\n",
    "                                    feed_dict={x:train_x, z_sample:train_z_sample})\n",
    "        \n",
    "            tot_loss = loss_likelihood + d_loss + g_loss\n",
    "            print(\" >> [%03d - %d/%d]: L_tot %03.2f, L_likelihood %03.2f, d_loss %03.2f, g_loss %03.2f\" % (epoch, i, total_batch, tot_loss, loss_likelihood, d_loss, g_loss))\n",
    "        \n",
    "        # print cost every epoch\n",
    "        print(\"epoch %03d: L_tot %03.2f, L_likelihood %03.2f, d_loss %03.2f, g_loss %03.2f\" % (epoch, tot_loss, loss_likelihood, d_loss, g_loss))\n",
    "        test_x = reader.next_batch(False)\n",
    "        test_x = test_x / 255.0\n",
    "        \n",
    "        test_y = sess.run(y, feed_dict={x:test_x})\n",
    "        \n",
    "        test_images=np.array([test_x, test_y])\n",
    "        #Image.fromarray(merge_images(test_images, direction=\"V\")).show()\n",
    "        save_images(test_images, os.path.join('/Users/kimsu/Desktop/kimsu/01_study/05_src/anomaly_detection/master/result', 'RECON_%03d.png'.format(epoch)))\n",
    "    \n",
    "        \n",
    "        if epoch % MODEL_SAVE_INTERVAL_EPOCH:\n",
    "            # Save the model\n",
    "            save_name=\"%s_%03d.ckpt\".format(os.path.join(MODEL_DIR, model_name), epoch)\n",
    "            saver.save(sess, save_name)\n",
    "            print('Trained Model Saved.: %s'.format(save_name))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 형태 만들어 놓고,\n",
    "save_name=\"%s_001.ckpt\".format(os.path.join(MODEL_DIR, model_name))\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/Users/kimsu/Desktop/kimsu/01_study/05_src/anomaly_detection/dataset/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/Test001',\n",
       "  ['001.tif',\n",
       "   '002.tif',\n",
       "   '003.tif',\n",
       "   '004.tif',\n",
       "   '005.tif',\n",
       "   '006.tif',\n",
       "   '007.tif',\n",
       "   '008.tif',\n",
       "   '009.tif',\n",
       "   '010.tif',\n",
       "   '011.tif',\n",
       "   '012.tif',\n",
       "   '013.tif',\n",
       "   '014.tif',\n",
       "   '015.tif',\n",
       "   '016.tif',\n",
       "   '017.tif',\n",
       "   '018.tif',\n",
       "   '019.tif',\n",
       "   '020.tif',\n",
       "   '021.tif',\n",
       "   '022.tif',\n",
       "   '023.tif',\n",
       "   '024.tif',\n",
       "   '025.tif',\n",
       "   '026.tif',\n",
       "   '027.tif',\n",
       "   '028.tif',\n",
       "   '029.tif',\n",
       "   '030.tif',\n",
       "   '031.tif',\n",
       "   '032.tif',\n",
       "   '033.tif',\n",
       "   '034.tif',\n",
       "   '035.tif',\n",
       "   '036.tif',\n",
       "   '037.tif',\n",
       "   '038.tif',\n",
       "   '039.tif',\n",
       "   '040.tif',\n",
       "   '041.tif',\n",
       "   '042.tif',\n",
       "   '043.tif',\n",
       "   '044.tif',\n",
       "   '045.tif',\n",
       "   '046.tif',\n",
       "   '047.tif',\n",
       "   '048.tif',\n",
       "   '049.tif',\n",
       "   '050.tif',\n",
       "   '051.tif',\n",
       "   '052.tif',\n",
       "   '053.tif',\n",
       "   '054.tif',\n",
       "   '055.tif',\n",
       "   '056.tif',\n",
       "   '057.tif',\n",
       "   '058.tif',\n",
       "   '059.tif',\n",
       "   '060.tif',\n",
       "   '061.tif',\n",
       "   '062.tif',\n",
       "   '063.tif',\n",
       "   '064.tif',\n",
       "   '065.tif',\n",
       "   '066.tif',\n",
       "   '067.tif',\n",
       "   '068.tif',\n",
       "   '069.tif',\n",
       "   '070.tif',\n",
       "   '071.tif',\n",
       "   '072.tif',\n",
       "   '073.tif',\n",
       "   '074.tif',\n",
       "   '075.tif',\n",
       "   '076.tif',\n",
       "   '077.tif',\n",
       "   '078.tif',\n",
       "   '079.tif',\n",
       "   '080.tif',\n",
       "   '081.tif',\n",
       "   '082.tif',\n",
       "   '083.tif',\n",
       "   '084.tif',\n",
       "   '085.tif',\n",
       "   '086.tif',\n",
       "   '087.tif',\n",
       "   '088.tif',\n",
       "   '089.tif',\n",
       "   '090.tif',\n",
       "   '091.tif',\n",
       "   '092.tif',\n",
       "   '093.tif',\n",
       "   '094.tif',\n",
       "   '095.tif',\n",
       "   '096.tif',\n",
       "   '097.tif',\n",
       "   '098.tif',\n",
       "   '099.tif',\n",
       "   '100.tif',\n",
       "   '101.tif',\n",
       "   '102.tif',\n",
       "   '103.tif',\n",
       "   '104.tif',\n",
       "   '105.tif',\n",
       "   '106.tif',\n",
       "   '107.tif',\n",
       "   '108.tif',\n",
       "   '109.tif',\n",
       "   '110.tif',\n",
       "   '111.tif',\n",
       "   '112.tif',\n",
       "   '113.tif',\n",
       "   '114.tif',\n",
       "   '115.tif',\n",
       "   '116.tif',\n",
       "   '117.tif',\n",
       "   '118.tif',\n",
       "   '119.tif',\n",
       "   '120.tif',\n",
       "   '121.tif',\n",
       "   '122.tif',\n",
       "   '123.tif',\n",
       "   '124.tif',\n",
       "   '125.tif',\n",
       "   '126.tif',\n",
       "   '127.tif',\n",
       "   '128.tif',\n",
       "   '129.tif',\n",
       "   '130.tif',\n",
       "   '131.tif',\n",
       "   '132.tif',\n",
       "   '133.tif',\n",
       "   '134.tif',\n",
       "   '135.tif',\n",
       "   '136.tif',\n",
       "   '137.tif',\n",
       "   '138.tif',\n",
       "   '139.tif',\n",
       "   '140.tif',\n",
       "   '141.tif',\n",
       "   '142.tif',\n",
       "   '143.tif',\n",
       "   '144.tif',\n",
       "   '145.tif',\n",
       "   '146.tif',\n",
       "   '147.tif',\n",
       "   '148.tif',\n",
       "   '149.tif',\n",
       "   '150.tif',\n",
       "   '151.tif',\n",
       "   '152.tif',\n",
       "   '153.tif',\n",
       "   '154.tif',\n",
       "   '155.tif',\n",
       "   '156.tif',\n",
       "   '157.tif',\n",
       "   '158.tif',\n",
       "   '159.tif',\n",
       "   '160.tif',\n",
       "   '161.tif',\n",
       "   '162.tif',\n",
       "   '163.tif',\n",
       "   '164.tif',\n",
       "   '165.tif',\n",
       "   '166.tif',\n",
       "   '167.tif',\n",
       "   '168.tif',\n",
       "   '169.tif',\n",
       "   '170.tif',\n",
       "   '171.tif',\n",
       "   '172.tif',\n",
       "   '173.tif',\n",
       "   '174.tif',\n",
       "   '175.tif',\n",
       "   '176.tif',\n",
       "   '177.tif',\n",
       "   '178.tif',\n",
       "   '179.tif',\n",
       "   '180.tif',\n",
       "   '181.tif',\n",
       "   '182.tif',\n",
       "   '183.tif',\n",
       "   '184.tif',\n",
       "   '185.tif',\n",
       "   '186.tif',\n",
       "   '187.tif',\n",
       "   '188.tif',\n",
       "   '189.tif',\n",
       "   '190.tif',\n",
       "   '191.tif',\n",
       "   '192.tif',\n",
       "   '193.tif',\n",
       "   '194.tif',\n",
       "   '195.tif',\n",
       "   '196.tif',\n",
       "   '197.tif',\n",
       "   '198.tif',\n",
       "   '199.tif',\n",
       "   '200.tif']],\n",
       " ['/Users/kimsu/Desktop/kimsu/01_study/05_src/anomaly_detection/dataset/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/Test002',\n",
       "  ['001.tif',\n",
       "   '002.tif',\n",
       "   '003.tif',\n",
       "   '004.tif',\n",
       "   '005.tif',\n",
       "   '006.tif',\n",
       "   '007.tif',\n",
       "   '008.tif',\n",
       "   '009.tif',\n",
       "   '010.tif',\n",
       "   '011.tif',\n",
       "   '012.tif',\n",
       "   '013.tif',\n",
       "   '014.tif',\n",
       "   '015.tif',\n",
       "   '016.tif',\n",
       "   '017.tif',\n",
       "   '018.tif',\n",
       "   '019.tif',\n",
       "   '020.tif',\n",
       "   '021.tif',\n",
       "   '022.tif',\n",
       "   '023.tif',\n",
       "   '024.tif',\n",
       "   '025.tif',\n",
       "   '026.tif',\n",
       "   '027.tif',\n",
       "   '028.tif',\n",
       "   '029.tif',\n",
       "   '030.tif',\n",
       "   '031.tif',\n",
       "   '032.tif',\n",
       "   '033.tif',\n",
       "   '034.tif',\n",
       "   '035.tif',\n",
       "   '036.tif',\n",
       "   '037.tif',\n",
       "   '038.tif',\n",
       "   '039.tif',\n",
       "   '040.tif',\n",
       "   '041.tif',\n",
       "   '042.tif',\n",
       "   '043.tif',\n",
       "   '044.tif',\n",
       "   '045.tif',\n",
       "   '046.tif',\n",
       "   '047.tif',\n",
       "   '048.tif',\n",
       "   '049.tif',\n",
       "   '050.tif',\n",
       "   '051.tif',\n",
       "   '052.tif',\n",
       "   '053.tif',\n",
       "   '054.tif',\n",
       "   '055.tif',\n",
       "   '056.tif',\n",
       "   '057.tif',\n",
       "   '058.tif',\n",
       "   '059.tif',\n",
       "   '060.tif',\n",
       "   '061.tif',\n",
       "   '062.tif',\n",
       "   '063.tif',\n",
       "   '064.tif',\n",
       "   '065.tif',\n",
       "   '066.tif',\n",
       "   '067.tif',\n",
       "   '068.tif',\n",
       "   '069.tif',\n",
       "   '070.tif',\n",
       "   '071.tif',\n",
       "   '072.tif',\n",
       "   '073.tif',\n",
       "   '074.tif',\n",
       "   '075.tif',\n",
       "   '076.tif',\n",
       "   '077.tif',\n",
       "   '078.tif',\n",
       "   '079.tif',\n",
       "   '080.tif',\n",
       "   '081.tif',\n",
       "   '082.tif',\n",
       "   '083.tif',\n",
       "   '084.tif',\n",
       "   '085.tif',\n",
       "   '086.tif',\n",
       "   '087.tif',\n",
       "   '088.tif',\n",
       "   '089.tif',\n",
       "   '090.tif',\n",
       "   '091.tif',\n",
       "   '092.tif',\n",
       "   '093.tif',\n",
       "   '094.tif',\n",
       "   '095.tif',\n",
       "   '096.tif',\n",
       "   '097.tif',\n",
       "   '098.tif',\n",
       "   '099.tif',\n",
       "   '100.tif',\n",
       "   '101.tif',\n",
       "   '102.tif',\n",
       "   '103.tif',\n",
       "   '104.tif',\n",
       "   '105.tif',\n",
       "   '106.tif',\n",
       "   '107.tif',\n",
       "   '108.tif',\n",
       "   '109.tif',\n",
       "   '110.tif',\n",
       "   '111.tif',\n",
       "   '112.tif',\n",
       "   '113.tif',\n",
       "   '114.tif',\n",
       "   '115.tif',\n",
       "   '116.tif',\n",
       "   '117.tif',\n",
       "   '118.tif',\n",
       "   '119.tif',\n",
       "   '120.tif',\n",
       "   '121.tif',\n",
       "   '122.tif',\n",
       "   '123.tif',\n",
       "   '124.tif',\n",
       "   '125.tif',\n",
       "   '126.tif',\n",
       "   '127.tif',\n",
       "   '128.tif',\n",
       "   '129.tif',\n",
       "   '130.tif',\n",
       "   '131.tif',\n",
       "   '132.tif',\n",
       "   '133.tif',\n",
       "   '134.tif',\n",
       "   '135.tif',\n",
       "   '136.tif',\n",
       "   '137.tif',\n",
       "   '138.tif',\n",
       "   '139.tif',\n",
       "   '140.tif',\n",
       "   '141.tif',\n",
       "   '142.tif',\n",
       "   '143.tif',\n",
       "   '144.tif',\n",
       "   '145.tif',\n",
       "   '146.tif',\n",
       "   '147.tif',\n",
       "   '148.tif',\n",
       "   '149.tif',\n",
       "   '150.tif',\n",
       "   '151.tif',\n",
       "   '152.tif',\n",
       "   '153.tif',\n",
       "   '154.tif',\n",
       "   '155.tif',\n",
       "   '156.tif',\n",
       "   '157.tif',\n",
       "   '158.tif',\n",
       "   '159.tif',\n",
       "   '160.tif',\n",
       "   '161.tif',\n",
       "   '162.tif',\n",
       "   '163.tif',\n",
       "   '164.tif',\n",
       "   '165.tif',\n",
       "   '166.tif',\n",
       "   '167.tif',\n",
       "   '168.tif',\n",
       "   '169.tif',\n",
       "   '170.tif',\n",
       "   '171.tif',\n",
       "   '172.tif',\n",
       "   '173.tif',\n",
       "   '174.tif',\n",
       "   '175.tif',\n",
       "   '176.tif',\n",
       "   '177.tif',\n",
       "   '178.tif',\n",
       "   '179.tif',\n",
       "   '180.tif',\n",
       "   '181.tif',\n",
       "   '182.tif',\n",
       "   '183.tif',\n",
       "   '184.tif',\n",
       "   '185.tif',\n",
       "   '186.tif',\n",
       "   '187.tif',\n",
       "   '188.tif',\n",
       "   '189.tif',\n",
       "   '190.tif',\n",
       "   '191.tif',\n",
       "   '192.tif',\n",
       "   '193.tif',\n",
       "   '194.tif',\n",
       "   '195.tif',\n",
       "   '196.tif',\n",
       "   '197.tif',\n",
       "   '198.tif',\n",
       "   '199.tif',\n",
       "   '200.tif']]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.testFileList[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=reader.next_batch()\n",
    "#images2=reader.next_batch()\n",
    "images2=images.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 224, 224, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 224, 224, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np = np.array([images[0], images[1]])\n",
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=reader.next_batch(False)\n",
    "#images2=reader.next_batch()\n",
    "images2=images.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 8, 224, 224, 1), (2, 8, 224, 224, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, images2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot_Reproduce_Performance():\n",
    "    def __init__(self, DIR, n_img_x=8, n_img_y=8, img_w=28, img_h=28, resize_factor=1.0):\n",
    "        self.DIR = DIR\n",
    "\n",
    "        assert n_img_x > 0 and n_img_y > 0\n",
    "\n",
    "        self.n_img_x = n_img_x\n",
    "        self.n_img_y = n_img_y\n",
    "        self.n_tot_imgs = n_img_x * n_img_y\n",
    "\n",
    "        assert img_w > 0 and img_h > 0\n",
    "\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "\n",
    "        assert resize_factor > 0\n",
    "\n",
    "        self.resize_factor = resize_factor\n",
    "\n",
    "    def save_images(self, images, name='result.jpg'):\n",
    "        images = images.reshape(self.n_img_x*self.n_img_y, self.img_h, self.img_w)\n",
    "        imsave(self.DIR + \"/\"+name, self._merge(images, [self.n_img_y, self.n_img_x]))\n",
    "\n",
    "    def _merge(self, images, direction=\"V\"):\n",
    "        # images: [b, d, h, w, c]\n",
    "        batch_size=images.shape[0]\n",
    "        depth = images.shape[1]\n",
    "        if len(images.shape) == 5 and images.shape[4] == 1:\n",
    "            images=images[:,:,:,:,0]\n",
    "        h, w = images.shape[2], images.shape[3]\n",
    "\n",
    "        h_ = int(h * self.resize_factor)\n",
    "        w_ = int(w * self.resize_factor)\n",
    "        \n",
    "        if direction == \"V\":\n",
    "            img = np.zeros((h_ * depth, w_ * batch_size))\n",
    "        else:\n",
    "            img = np.zeros((h_ * batch_size, w_ * depth))\n",
    "        \n",
    "        if direction == \"V\":\n",
    "            for r in range(depth):\n",
    "                for c in range(batch_size):\n",
    "                    image_ = imresize(images[c][r], size=(w_,h_), interp='bicubic')\n",
    "                    img[r*h_:r*h_+h_, c*w_:c*w_+w_] = image_\n",
    "        else:\n",
    "            for r in range(batch_size):\n",
    "                for c in range(depth):\n",
    "                    image_ = imresize(images[r][c], size=(w_,h_), interp='bicubic')\n",
    "                    img[r*h_:r*h_+h_, c*w_:c*w_+w_] = image_\n",
    "\n",
    "        return img\n",
    "        \n",
    "#         img = np.zeros((h_ * size[0], w_ * size[1]))\n",
    "\n",
    "#         for idx, image in enumerate(images):\n",
    "#             i = int(idx % size[1])\n",
    "#             j = int(idx / size[1])\n",
    "\n",
    "#             image_ = imresize(image, size=(w_,h_), interp='bicubic')\n",
    "\n",
    "#             img[j*h_:j*h_+h_, i*w_:i*w_+w_] = image_\n",
    "\n",
    "#         return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRR=Plot_Reproduce_Performance(\"test\", 2, num_frames_per_clip, IMAGE_CROP_SIZE, IMAGE_CROP_SIZE, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsu/py36tf1x/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    }
   ],
   "source": [
    "images=reader.next_batch(False)\n",
    "\n",
    "img=merge_images(images, 1.0, \"V\")\n",
    "im = Image.fromarray(img)\n",
    "im.\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 224, 224, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsu/py36tf1x/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tmp=imresize(images[0,1,:,:,0], size=(30, 40), interp='bicubic')\n",
    "img_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im2=Image.fromarray(img_tmp)\n",
    "im2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = Image.fromarray(img_tmp)\n",
    "im.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36tf1x",
   "language": "python",
   "name": "py36tf1x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
